{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画像認識による乗り物分類レシピ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://axross-recipe.com/recipes/1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flickr API の準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下の３つの乗り物の画像を分類する\n",
    "- 電車\n",
    "- 車\n",
    "- 自転車"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import time\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "from flickrapi import FlickrAPI\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APIキー情報\n",
    "FLICKR_KEY = os.environ['FLICKR_KEY']\n",
    "FLICKR_SECRET = os.environ['FLICKR_SECRET']\n",
    "\n",
    "# 乗り物の名前\n",
    "VEHICLES = [\"train\", \"car\", \"bicycle\"]\n",
    "\n",
    "# 乗り物をループしてデータを取得\n",
    "for vehicle in VEHICLES:\n",
    "    # 保存フォルダの指定\n",
    "    save_dir = os.path.join(\"datasets\", vehicle)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Flickr APIの初期化\n",
    "    flickr = FlickrAPI(FLICKR_KEY, FLICKR_SECRET, format=\"parsed-json\")\n",
    "    \n",
    "    # 乗り物の名前を指定して100件の画像情報を取得\n",
    "    result = flickr.photos.search(text=vehicle,\n",
    "                                                      per_page=100,\n",
    "                                                      media=\"photos\",\n",
    "                                                      sort=\"relavance\",\n",
    "                                                      safe_search=1,\n",
    "                                                      extras=\"url_q, licence\")\n",
    "    \n",
    "    # 画像情報から実際の画像ファイルを取得\n",
    "    photos = result[\"photos\"]\n",
    "    for photo in photos[\"photo\"]:\n",
    "        # 画像のURL\n",
    "        url_q = photo[\"url_q\"]\n",
    "        # 画像のダウンロード先\n",
    "        filepath = os.path.join(save_dir, photo[\"id\"] + \".jpg\")\n",
    "        # 画像を指定したパスにダウンロードして保存\n",
    "        urlretrieve(url_q, filepath)\n",
    "        # クローリング先のサーバーに負荷を与えない\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットを交差検証用に分割する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乗り物の名前\n",
    "VEHICLES = [\"train\", \"car\", \"bicycle\"]\n",
    "# データセットのフォルダパス\n",
    "DATASET_DIR = os.path.join(\"datasets\")\n",
    "\n",
    "datasets = []\n",
    "labels = []\n",
    "\n",
    "for index, label in enumerate(VEHICLES):\n",
    "    # 画像の読み込み\n",
    "    photos_dir = os.path.join(DATASET_DIR, label)\n",
    "    filepaths = glob.glob(os.path.join(photos_dir, \"*.jpg\"))\n",
    "    \n",
    "    # 画像を順次処理してデータセットを作成\n",
    "    for i, filepath in enumerate(filepaths):\n",
    "        # 各乗り物のデータを100に揃える\n",
    "        if i >= 100:\n",
    "            break\n",
    "        \n",
    "        # 画像の読み込み\n",
    "        image = Image.open(filepath)\n",
    "        # RGBの3色に変換\n",
    "        image = image.convert(\"RGB\")\n",
    "        # 画像のサイズを統一\n",
    "        image = image.resize((50, 50))\n",
    "        # 画像を数値の配列に変換\n",
    "        dataset = np.asarray(image)\n",
    "        # データセットを追加\n",
    "        datasets.append(dataset)\n",
    "        # ラベルを追加\n",
    "        labels.append(index)\n",
    "\n",
    "# Tensorflow がデータを処理しやすいように numpy の array に変換\n",
    "datasets = np.array(datasets)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# データセットとラベルの両方を学習データとテストデータに分類\n",
    "dataset_train, dataset_test, label_train, label_test = model_selection.train_test_split(datasets, labels)\n",
    "\n",
    "# 分類したデータをファイルに保存\n",
    "data = (dataset_train, dataset_test, label_train, label_test)\n",
    "np.save(os.path.join(DATASET_DIR, \"vehicle.npy\"), data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルのトレーニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import (Activation, Conv2D, Dense, Dropout, Flatten, MaxPooling2D)\n",
    "from keras.models import Sequentialfrom keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乗り物の名前\n",
    "VEHICLES = [\"train\", \"car\", \"bicycle\"]\n",
    "# データセットのフォリダパス\n",
    "DATASET_DIR = os.path.join(\"datasets\")\n",
    "\n",
    "# データセットの読み込み\n",
    "dataset_train, dataset_test, label_train, label_test = np.load(os.path.join(DATASET_DIR, \"vehicle.npy\"), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画素を0〜1の範囲に変換（正規化）\n",
    "dataset_train = dataset_train.astype(\"float\") / 256\n",
    "dataset_test = dataset_test.astype(\"float\") / 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベルを one-hotエンコーディング\n",
    "label_train = np_utils.to_categorical(label_train, len(VEHICLES))\n",
    "label_test = np_utils.to_categorical(label_test, len(VEHICLES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 1.1167 - accuracy: 0.3616\n",
      "Epoch 2/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 1.0922 - accuracy: 0.3705\n",
      "Epoch 3/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 1.0724 - accuracy: 0.4152\n",
      "Epoch 4/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 1.0601 - accuracy: 0.4464\n",
      "Epoch 5/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 1.0412 - accuracy: 0.4955\n",
      "Epoch 6/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 1.0297 - accuracy: 0.5179\n",
      "Epoch 7/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 1.0030 - accuracy: 0.5134\n",
      "Epoch 8/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.9834 - accuracy: 0.5045\n",
      "Epoch 9/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.9474 - accuracy: 0.6071\n",
      "Epoch 10/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.9622 - accuracy: 0.5670\n",
      "Epoch 11/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.9202 - accuracy: 0.5670\n",
      "Epoch 12/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.9231 - accuracy: 0.6027\n",
      "Epoch 13/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.9117 - accuracy: 0.5982\n",
      "Epoch 14/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.8736 - accuracy: 0.6518\n",
      "Epoch 15/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.8383 - accuracy: 0.6473\n",
      "Epoch 16/100\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.8120 - accuracy: 0.6562\n",
      "Epoch 17/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.8262 - accuracy: 0.6473\n",
      "Epoch 18/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.7931 - accuracy: 0.6161\n",
      "Epoch 19/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.8048 - accuracy: 0.6607\n",
      "Epoch 20/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.7606 - accuracy: 0.6830\n",
      "Epoch 21/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.7384 - accuracy: 0.6741\n",
      "Epoch 22/100\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.7457 - accuracy: 0.6473\n",
      "Epoch 23/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.7594 - accuracy: 0.6920\n",
      "Epoch 24/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6846 - accuracy: 0.7277\n",
      "Epoch 25/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.7108 - accuracy: 0.6741\n",
      "Epoch 26/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.7247 - accuracy: 0.6741\n",
      "Epoch 27/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6770 - accuracy: 0.7143\n",
      "Epoch 28/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6969 - accuracy: 0.7188\n",
      "Epoch 29/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6413 - accuracy: 0.7500\n",
      "Epoch 30/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6314 - accuracy: 0.7812\n",
      "Epoch 31/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.5854 - accuracy: 0.7812\n",
      "Epoch 32/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6568 - accuracy: 0.7366\n",
      "Epoch 33/100\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.5696 - accuracy: 0.8036\n",
      "Epoch 34/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6174 - accuracy: 0.7455\n",
      "Epoch 35/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.5932 - accuracy: 0.7589\n",
      "Epoch 36/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.5765 - accuracy: 0.7902\n",
      "Epoch 37/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.5634 - accuracy: 0.7902\n",
      "Epoch 38/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.5237 - accuracy: 0.7902\n",
      "Epoch 39/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.5432 - accuracy: 0.7946\n",
      "Epoch 40/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.5198 - accuracy: 0.8036\n",
      "Epoch 41/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.5541 - accuracy: 0.7902\n",
      "Epoch 42/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.5113 - accuracy: 0.8125\n",
      "Epoch 43/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.4697 - accuracy: 0.8393\n",
      "Epoch 44/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.5004 - accuracy: 0.8438\n",
      "Epoch 45/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.4620 - accuracy: 0.8393\n",
      "Epoch 46/100\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.4507 - accuracy: 0.8527\n",
      "Epoch 47/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.4141 - accuracy: 0.8750\n",
      "Epoch 48/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.4501 - accuracy: 0.8304\n",
      "Epoch 49/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.3981 - accuracy: 0.8839\n",
      "Epoch 50/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.4021 - accuracy: 0.8482\n",
      "Epoch 51/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.3952 - accuracy: 0.8661\n",
      "Epoch 52/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.4044 - accuracy: 0.8616\n",
      "Epoch 53/100\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.3746 - accuracy: 0.8929\n",
      "Epoch 54/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.3241 - accuracy: 0.8973\n",
      "Epoch 55/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.3859 - accuracy: 0.8705\n",
      "Epoch 56/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.3561 - accuracy: 0.8750\n",
      "Epoch 57/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.3124 - accuracy: 0.9018\n",
      "Epoch 58/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.2973 - accuracy: 0.9018\n",
      "Epoch 59/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.3372 - accuracy: 0.8705\n",
      "Epoch 60/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.3315 - accuracy: 0.9018\n",
      "Epoch 61/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.3174 - accuracy: 0.8973\n",
      "Epoch 62/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.2761 - accuracy: 0.8929\n",
      "Epoch 63/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.2703 - accuracy: 0.9107\n",
      "Epoch 64/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.2223 - accuracy: 0.9420\n",
      "Epoch 65/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.2744 - accuracy: 0.8973\n",
      "Epoch 66/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.2466 - accuracy: 0.9330\n",
      "Epoch 67/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.2154 - accuracy: 0.9375\n",
      "Epoch 68/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.2133 - accuracy: 0.9420\n",
      "Epoch 69/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.2275 - accuracy: 0.9330\n",
      "Epoch 70/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.2337 - accuracy: 0.9330\n",
      "Epoch 71/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.1986 - accuracy: 0.9554\n",
      "Epoch 72/100\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.2900 - accuracy: 0.9062\n",
      "Epoch 73/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.1556 - accuracy: 0.9821\n",
      "Epoch 74/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.1704 - accuracy: 0.9509\n",
      "Epoch 75/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.1890 - accuracy: 0.9286\n",
      "Epoch 76/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.1755 - accuracy: 0.9643\n",
      "Epoch 77/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.1549 - accuracy: 0.9464\n",
      "Epoch 78/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.1820 - accuracy: 0.9554\n",
      "Epoch 79/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.1549 - accuracy: 0.9509\n",
      "Epoch 80/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.1257 - accuracy: 0.9598\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/224 [==============================] - 1s 5ms/step - loss: 0.2074 - accuracy: 0.9241\n",
      "Epoch 82/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.1112 - accuracy: 0.9777\n",
      "Epoch 83/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.1553 - accuracy: 0.9554\n",
      "Epoch 84/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.1353 - accuracy: 0.9554\n",
      "Epoch 85/100\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.1143 - accuracy: 0.9777\n",
      "Epoch 86/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.1226 - accuracy: 0.9643\n",
      "Epoch 87/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.1501 - accuracy: 0.9420\n",
      "Epoch 88/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.0981 - accuracy: 0.9777\n",
      "Epoch 89/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.1004 - accuracy: 0.9777\n",
      "Epoch 90/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.1058 - accuracy: 0.9732\n",
      "Epoch 91/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.1478 - accuracy: 0.9554\n",
      "Epoch 92/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.1071 - accuracy: 0.9688\n",
      "Epoch 93/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.0944 - accuracy: 0.9732\n",
      "Epoch 94/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.1157 - accuracy: 0.9643\n",
      "Epoch 95/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.0950 - accuracy: 0.9777\n",
      "Epoch 96/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.0956 - accuracy: 0.9777\n",
      "Epoch 97/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.0708 - accuracy: 0.9777\n",
      "Epoch 98/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.0931 - accuracy: 0.9643\n",
      "Epoch 99/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.0592 - accuracy: 0.9911\n",
      "Epoch 100/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.1257 - accuracy: 0.9509\n"
     ]
    }
   ],
   "source": [
    "# モデルの定義\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=dataset_train.shape[1:]))\n",
    "\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "# RMSprop最適化関数\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "                          optimizer=opt,\n",
    "                          metrics=[\"accuracy\"])\n",
    "\n",
    "# モデルのトレーニング\n",
    "model.fit(dataset_train, label_train, batch_size=32, epochs=100)\n",
    "\n",
    "# モデルの保存\n",
    "model.save(os.path.join(DATASET_DIR, \"vehicle_cnn.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルのテストと評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 1ms/step\n",
      "LOSS: 1.3743815008799236\n",
      "Accuracy: 0.6266666650772095\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(dataset_test, label_test, verbose=1)\n",
    "\n",
    "print(\"LOSS: \" + str(scores[0]))\n",
    "print(\"Accuracy: \" + str(scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 を使った転移学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "元となる学習済みのモデルの層をフリーズ（再学習しない）して、学習済みモデルの最後に新しい層を追加していく。\n",
    "今回は、VGG16 の最後に３つの乗り物のクラスで定義された層を追加していく。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import (Activation, Conv2D, Dense, Dropout, Flatten,\n",
    "                          MaxPooling2D)\n",
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 50, 50, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 50, 50, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 50, 50, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 25, 25, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 25, 25, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 6, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_5 (Sequential)    (None, 3)                 132099    \n",
      "=================================================================\n",
      "Total params: 14,846,787\n",
      "Trainable params: 14,846,787\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# VGG16モデルの読み込み（ImgaeNet）\n",
    "vgg_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=dataset_train.shape[1:])\n",
    "\n",
    "# 新しいモデルの定義\n",
    "new_model = Sequential()\n",
    "new_model.add(Flatten(input_shape=vgg_model.output_shape[1:]))\n",
    "new_model.add(Dense(256, activation=\"relu\"))\n",
    "new_model.add(Dropout(0.5))\n",
    "new_model.add(Dense(len(VEHICLES), activation=\"softmax\"))\n",
    "\n",
    "# VGG16と新しい層を結合\n",
    "# VGG16モデルの出力を新しいモデルに渡す\n",
    "model = Model(inputs=vgg_model.input, outputs=new_model(vgg_model.output))\n",
    "\n",
    "# モデルの層を確認\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 1.4870 - accuracy: 0.3080\n",
      "Epoch 2/30\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 1.2873 - accuracy: 0.3438\n",
      "Epoch 3/30\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 1.2401 - accuracy: 0.3571\n",
      "Epoch 4/30\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 1.2133 - accuracy: 0.3348\n",
      "Epoch 5/30\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 1.1547 - accuracy: 0.4330\n",
      "Epoch 6/30\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 1.1819 - accuracy: 0.3661\n",
      "Epoch 7/30\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 1.1151 - accuracy: 0.3884\n",
      "Epoch 8/30\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 1.1101 - accuracy: 0.4286\n",
      "Epoch 9/30\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 1.0975 - accuracy: 0.4554\n",
      "Epoch 10/30\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 1.0919 - accuracy: 0.4509\n",
      "Epoch 11/30\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 1.0016 - accuracy: 0.4955\n",
      "Epoch 12/30\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 1.0076 - accuracy: 0.4643\n",
      "Epoch 13/30\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.9088 - accuracy: 0.5714\n",
      "Epoch 14/30\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 1.0060 - accuracy: 0.5089\n",
      "Epoch 15/30\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.9482 - accuracy: 0.5536\n",
      "Epoch 16/30\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 1.0093 - accuracy: 0.4732\n",
      "Epoch 17/30\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.9353 - accuracy: 0.5536\n",
      "Epoch 18/30\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.9256 - accuracy: 0.5670\n",
      "Epoch 19/30\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.9072 - accuracy: 0.5670\n",
      "Epoch 20/30\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.9047 - accuracy: 0.5491\n",
      "Epoch 21/30\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.9322 - accuracy: 0.5759\n",
      "Epoch 22/30\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.8608 - accuracy: 0.6384\n",
      "Epoch 23/30\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.8373 - accuracy: 0.6562\n",
      "Epoch 24/30\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.8677 - accuracy: 0.5893\n",
      "Epoch 25/30\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.8167 - accuracy: 0.6473\n",
      "Epoch 26/30\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.8519 - accuracy: 0.5982\n",
      "Epoch 27/30\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.8047 - accuracy: 0.6429\n",
      "Epoch 28/30\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.8582 - accuracy: 0.5938\n",
      "Epoch 29/30\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.7743 - accuracy: 0.6875\n",
      "Epoch 30/30\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.8163 - accuracy: 0.6339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x14a8fd9b0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VGG16モデルの最初の18層をフリーズ\n",
    "# VGG16の層は再学習させずに新しく追加した最後の層だけを学習\n",
    "for layer in model.layers[:18]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# RMSprop最適化関数\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "                          optimizer=opt,\n",
    "                          metrics=[\"accuracy\"])\n",
    "\n",
    "# モデルのトレーニング\n",
    "model.fit(dataset_train, label_train, batch_size=32, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 5ms/step\n",
      "Loss: 0.8703115359942118\n",
      "Accuracy: 0.6666666865348816\n"
     ]
    }
   ],
   "source": [
    "# モデルの評価\n",
    "scores = model.evaluate(dataset_test, label_test, verbose = 1)\n",
    "print(\"Loss: \" + str(scores[0]))\n",
    "print(\"Accuracy: \" + str(scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.8128 - accuracy: 0.6250\n",
      "Epoch 2/10\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.7667 - accuracy: 0.6830\n",
      "Epoch 3/10\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.7408 - accuracy: 0.6830\n",
      "Epoch 4/10\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.7344 - accuracy: 0.6875\n",
      "Epoch 5/10\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.7453 - accuracy: 0.6562\n",
      "Epoch 6/10\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.7329 - accuracy: 0.6652\n",
      "Epoch 7/10\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.7172 - accuracy: 0.7232\n",
      "Epoch 8/10\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.7163 - accuracy: 0.7321\n",
      "Epoch 9/10\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6938 - accuracy: 0.7232\n",
      "Epoch 10/10\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6725 - accuracy: 0.7545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x14a04c7b8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルの再トレーニング\n",
    "model.fit(dataset_train, label_train, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 4ms/step\n",
      "Loss: 0.8402052434285482\n",
      "Accuracy: 0.6800000071525574\n"
     ]
    }
   ],
   "source": [
    "# モデルの評価\n",
    "scores = model.evaluate(dataset_test, label_test, verbose = 1)\n",
    "print(\"Loss: \" + str(scores[0]))\n",
    "print(\"Accuracy: \" + str(scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
